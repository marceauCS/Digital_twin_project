{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer,accuracy_score ,precision_score, recall_score\n",
    "from sklearn.metrics import f1_score,confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "from utility import read_all_test_data_from_path\n",
    "from utility import run_cv_one_motor\n",
    "from utility import extract_selected_feature, prepare_sliding_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_int = 20\n",
    "\n",
    "utility_path = '../'\n",
    "sys.path.insert(1, utility_path)\n",
    "\n",
    "# Subfunction for data preprocessing.\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    - Use ffil function to replace the invalid measurement with the previous value\n",
    "    '''\n",
    "    \n",
    "    def remove_outliers(df: pd.DataFrame):\n",
    "        ''' # Description\n",
    "        Remove outliers from the dataframe based on defined valid ranges. \n",
    "        Define a valid range of temperature and voltage. \n",
    "        Use ffil function to replace the invalid measurement with the previous value.\n",
    "        '''\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "        df['temperature'] = df['temperature'].ffill()        \n",
    "\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] <= 9000, np.nan)\n",
    "        df['voltage'] = df['voltage'].ffill()       \n",
    "\n",
    "        df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "        df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "        df['position'] = df['position'].ffill()\n",
    "        \n",
    "    def remove_seq_variability(df: pd.DataFrame):\n",
    "        ''' # Description\n",
    "        Remove the sequence-to-sequence variability.\n",
    "        '''\n",
    "        # Tranform the features relative to the first data point.\n",
    "        df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "        df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "        df['position'] = df['position'] - df['position'].iloc[0]\n",
    "\n",
    "    def cal_diff(df: pd.DataFrame, n_int: int):\n",
    "        ''' # Description\n",
    "        Calculate the difference between the current and previous n data point.\n",
    "        '''\n",
    "\n",
    "        # Calculate the difference between the current and previous n data point.\n",
    "        df['temperature_diff'] = df['temperature'].diff(n_int)\n",
    "        df['voltage_diff'] = df['voltage'].diff(n_int)\n",
    "        df['position_diff'] = df['position'].diff(n_int)   \n",
    "\n",
    "    # Start processing.\n",
    "    remove_outliers(df)\n",
    "    remove_seq_variability(df)\n",
    "    #cal_diff(df, n_int)\n",
    "    \n",
    "label_columns = ['data_motor_1_label', 'data_motor_2_label', 'data_motor_3_label', 'data_motor_4_label', 'data_motor_5_label', 'data_motor_6_label']\n",
    "    \n",
    "# Read all the training dataset.\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "df_data = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)\n",
    "\n",
    "# Smooth the data.\n",
    "smoothed_data = df_data.copy(deep=True)\n",
    "\n",
    "for i in range(1,7):\n",
    "    smoothed_data[f'data_motor_{i}_voltage'] = smooth_data_moving_average(smoothed_data[f'data_motor_{i}_voltage'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dictionary = '../../dataset/testing_data/'\n",
    "df_test = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)\n",
    "\n",
    "\n",
    "for i in range(1,7):\n",
    "    df_test[f'data_motor_{i}_voltage'] = smooth_data_moving_average(df_test[f'data_motor_{i}_voltage'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only uncomment the following code if you want to add the call_diff function to preprocessing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "base_dictionary = '../../dataset/testing_data/'\n",
    "# Get all the folders in the base_dictionary\n",
    "path_list = os.listdir(base_dictionary)\n",
    "# Only keep the folders, not the excel file.\n",
    "path_list_sorted = sorted(path_list)\n",
    "path_list = path_list_sorted[:-1]\n",
    "\n",
    "# Read the data.\n",
    "df_test = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    #tmp_df = read_all_csvs_one_test(path, tmp_path, pre_processing)\n",
    "    \n",
    "    ### ------------read_all_csvs_one_test --------------\n",
    "    \n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "    # Create an empty DataFrame to store the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the CSV files in the folder\n",
    "    for file in csv_files:\n",
    "        # Construct the full path to each CSV file\n",
    "        file_path = os.path.join(path, file)\n",
    "\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Drop the time. Will add later.\n",
    "        df = df.drop(labels=df.columns[0], axis=1)\n",
    "\n",
    "        # Apply the pre-processing.\n",
    "        if pre_processing:\n",
    "            pre_processing(df)\n",
    "\n",
    "        # Extract the file name (excluding the extension) to use as a prefix\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "\n",
    "        # Add a prefix to each column based on the file name\n",
    "        df = df.add_prefix(f'{file_name}_')\n",
    "\n",
    "        # Concatenate the current DataFrame with the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "    # Add time and test condition\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df['time'], combined_df], axis=1)\n",
    "\n",
    "    # Calculate the time difference since the first row\n",
    "    time_since_first_row = combined_df['time'] - combined_df['time'].iloc[0]\n",
    "    # Replace the 'time' column with the time difference\n",
    "    combined_df['time'] = time_since_first_row\n",
    "\n",
    "    combined_df.loc[:, 'test_condition'] = tmp_path\n",
    "\n",
    "    combined_df.drop(columns=label_columns, inplace= True)\n",
    "    \n",
    "    # Drop the NaN values, which represents the first n data points in the original dataframe.\n",
    "    #combined_df.dropna(inplace=True)\n",
    "\n",
    "    tmp_df = combined_df\n",
    "    \n",
    "    ### --------------------------------------------\n",
    "    \n",
    "    df_test = pd.concat([df_test, tmp_df])\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Read the test conditions\n",
    "df_test_conditions = pd.read_excel(base_dictionary+'Test conditions.xlsx')\n",
    "\n",
    "# Smooth the data.\n",
    "\n",
    "#df_test.drop(columns=['time','test_condition'], inplace=True)\n",
    "\n",
    "for i in range(1,7):\n",
    "    df_test[f'data_motor_{i}_voltage'] = smooth_data_moving_average(df_test[f'data_motor_{i}_voltage'], 10)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the test conditions you would like to include in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data_experiment = smoothed_data[smoothed_data['test_condition'].isin(['20240425_093699', '20240425_094425', '20240426_140055',\n",
    "                                                       #'20240503_164675', '20240503_165189',\n",
    "                                                       #'20240503_163963', '20240325_155003'])]\n",
    "\n",
    "\n",
    "# normal\n",
    "normal_test_id = ['20240105_164214',\n",
    "    '20240105_165300',\n",
    "    '20240105_165972',\n",
    "    '20240320_152031',\n",
    "    '20240320_153841',\n",
    "    '20240320_155664',\n",
    "    '20240321_122650',\n",
    "    '20240325_135213',\n",
    "    '20240325_152902',\n",
    "    '20240426_141190',\n",
    "    '20240426_141532',\n",
    "    '20240426_141602',\n",
    "    '20240426_141726',\n",
    "    '20240426_141938',\n",
    "    '20240426_141980',\n",
    "    '20240503_163963',\n",
    "    '20240503_164435',\n",
    "    '20240503_164675',\n",
    "    '20240503_165189']\n",
    "\n",
    "normal_test_id = ['20240105_164214',\n",
    "    '20240105_165300',\n",
    "    '20240105_165972',\n",
    "    '20240320_152031',\n",
    "    '20240320_153841',\n",
    "    '20240320_155664',\n",
    "    '20240321_122650',\n",
    "    '20240325_135213',\n",
    "    '20240325_152902',\n",
    "    '20240325_155003',\n",
    "    '20240425_093699',\n",
    "    '20240425_094425',\n",
    "    '20240426_140055',\n",
    "    '20240426_141190',\n",
    "    '20240426_141532',\n",
    "    '20240426_141602',\n",
    "    '20240426_141726',\n",
    "    '20240426_141938',\n",
    "    '20240426_141980',\n",
    "    '20240503_163963',\n",
    "    '20240503_164435',\n",
    "    '20240503_164675',\n",
    "    '20240503_165189',\n",
    "    '20240529_122361',\n",
    "    '20240529_122994',\n",
    "    '20240529_123223',\n",
    "    '20240529_123430',\n",
    "    '20240529_124333',\n",
    "    '20240529_125896',\n",
    "    '20240529_130680',\n",
    "    '20240529_131085',\n",
    "    '20240529_131373',\n",
    "    '20240529_131558',\n",
    "    '20240529_131755',\n",
    "    '20240529_132509',\n",
    "    '20240529_133879'\n",
    "]\n",
    "\n",
    "\n",
    "df_data_experiment = smoothed_data[smoothed_data['test_condition'].isin(normal_test_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation - Only for evaluation, not for submit Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_motors(motor_label, drop_list):\n",
    "    X = df_data_experiment.drop(columns=label_columns+drop_list)\n",
    "    y = df_data_experiment[motor_label]\n",
    "    \n",
    "    #X_train, y_train, X_test , y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(class_weight='balanced'),\n",
    "        'Decision Tree': DecisionTreeClassifier(class_weight='balanced'),\n",
    "        'Random Forest': RandomForestClassifier(class_weight='balanced'),\n",
    "        'Support Vector Machine': SVC(class_weight='balanced'),\n",
    "        'Gradient Boosting': GradientBoostingClassifier()\n",
    "    }\n",
    "\n",
    "    # Dictionary to store model performance metrics\n",
    "    model_metrics = {}\n",
    "\n",
    "    # Define hyperparameter grids\n",
    "    param_grids = {\n",
    "        'Logistic Regression': {'C': [0.1, 1, 10]},\n",
    "        'Decision Tree': {'max_depth': [None, 10, 20]},\n",
    "        'Random Forest': {'n_estimators': [50, 100, 200]},\n",
    "        'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},\n",
    "        'Gradient Boosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "    }\n",
    "\n",
    "    model_predictions = {}\n",
    "\n",
    "    # Perform cross-validation, hyperparameter tuning, and evaluation\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='f1')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        model_predictions[f'y_pred_{model_name.replace(\" \", \"_\")}'] = y_pred\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Store metrics in the dictionary\n",
    "        model_metrics[model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1\n",
    "        }\n",
    "        \n",
    "    # Update the summary table with the model performance metrics\n",
    "    summary_table = \"| Model                    | Accuracy | Precision | Recall | F1    |\\n\"\n",
    "    summary_table += \"|--------------------------|----------|-----------|--------|-------|\\n\"\n",
    "    for model_name, metrics in model_metrics.items():\n",
    "        summary_table += f\"| {model_name:25} | {metrics['Accuracy']*100:.2f}%   | {metrics['Precision']*100:.2f}%   | {metrics['Recall']*100:.2f}%  | {metrics['F1']*100:.2f}% |\\n\"\n",
    "\n",
    "    print(summary_table)        \n",
    "    \n",
    "    return model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model on testing data for submit Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_motors_validation(motor_label, drop_list):\n",
    "        \n",
    "    feature_list_all = df_data_experiment.drop(columns=drop_list + [\"test_condition\"] + label_columns).columns.tolist()\n",
    "\n",
    "    # Extract the features.\n",
    "    df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_all, motor_label, mdl_type='clf')\n",
    "\n",
    "    # Prepare the training data based on the defined sliding window.\n",
    "    window_size = 70\n",
    "    sample_step = 40\n",
    "    X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "    \n",
    "    # Define the classification model.\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Initialize models\n",
    "    #models = {\n",
    "    #    'Logistic Regression': LogisticRegression(class_weight='balanced'),\n",
    "    #    'Decision Tree': DecisionTreeClassifier(class_weight='balanced'),\n",
    "    #    'Random Forest': RandomForestClassifier(class_weight='balanced'),\n",
    "    #    'Support Vector Machine': SVC(class_weight='balanced'),\n",
    "    #    'Gradient Boosting': GradientBoostingClassifier()\n",
    "    #}\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(class_weight='balanced'),\n",
    "        'Support Vector Machine': SVC(class_weight='balanced'),\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Define hyperparameter grids\n",
    "    #param_grids = {\n",
    "    #    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
    "    #    'Decision Tree': {'max_depth': [20, 30]},\n",
    "    #    'Random Forest': {'n_estimators': [150]},\n",
    "    #    'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': ['scale']},\n",
    "    #    'Gradient Boosting': {'n_estimators': [100, 150], 'learning_rate': [0.1, 0.5, 1]}\n",
    "    #}\n",
    "    \n",
    "    # Define hyperparameter grids\n",
    "    param_grids = {\n",
    "        'Support Vector Machine': {'C': [0.01], 'gamma': ['scale']},\n",
    "        'Logistic Regression': {'C': [0.01]}\n",
    "    }\n",
    "\n",
    "    model_predictions = {}\n",
    "    best_params = {}\n",
    "    \n",
    "    # Perform cross-validation, hyperparameter tuning, and evaluation\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        # Create the pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', MinMaxScaler()), # Step 1 : Normalization\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        param_grid = {f'model__{key}': value for key, value in param_grids[model_name].items()}\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "        #grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='f1')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "        \n",
    "        ## Evaluate on test set\n",
    "        \n",
    "        feature_list_all = df_data_experiment.drop(columns=label_columns+drop_list).columns.tolist()\n",
    "        \n",
    "        df_test_x = df_test[feature_list_all]\n",
    "    \n",
    "        X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "    \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        model_predictions[f'y_pred_{model_name.replace(\" \", \"_\")}'] = y_pred    \n",
    "    \n",
    "    return model_predictions, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1_label1 = ['data_motor_2_voltage', 'data_motor_3_voltage', 'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage', 'data_motor_6_position']\n",
    "\n",
    "drop_list2_label1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                    | Accuracy | Precision | Recall | F1    |\n",
      "|--------------------------|----------|-----------|--------|-------|\n",
      "| Logistic Regression       | 87.42%   | 0.00%   | 0.00%  | 0.00% |\n",
      "| Decision Tree             | 99.82%   | 99.64%   | 98.92%  | 99.28% |\n",
      "| Random Forest             | 99.82%   | 100.00%   | 98.56%  | 99.27% |\n",
      "| Support Vector Machine    | 87.42%   | 0.00%   | 0.00%  | 0.00% |\n",
      "| Gradient Boosting         | 99.77%   | 99.64%   | 98.56%  | 99.09% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions = run_all_motors('data_motor_1_label',drop_list1_label1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions, best_params1 = run_all_motors_validation(1, drop_list1_label1)\n",
    "#model_predictions, best_params1 = run_all_motors_validation(1, drop_list2_label1)\n",
    "\n",
    "#y_pred1_Gradient_Boosting = model_predictions['y_pred_Gradient_Boosting']\n",
    "y_pred1_Logistic_Regression = model_predictions['y_pred_Logistic_Regression']\n",
    "#y_pred1_Decision_Tree = model_predictions['y_pred_Decision_Tree']\n",
    "#y_pred1_Random_Forest= model_predictions['y_pred_Random_Forest']\n",
    "y_pred1_SVC= model_predictions['y_pred_Support_Vector_Machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'model__C': 0.01},\n",
       " 'Support Vector Machine': {'model__C': 0.01, 'model__gamma': 'scale'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1_label2 = ['data_motor_1_voltage', 'data_motor_3_voltage', 'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage', 'data_motor_5_temperature']\n",
    "\n",
    "drop_list2_label2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                    | Accuracy | Precision | Recall | F1    |\n",
      "|--------------------------|----------|-----------|--------|-------|\n",
      "| Logistic Regression       | 89.33%   | 24.98%   | 96.81%  | 39.71% |\n",
      "| Decision Tree             | 99.23%   | 82.84%   | 99.29%  | 90.32% |\n",
      "| Random Forest             | 99.86%   | 96.89%   | 99.29%  | 98.07% |\n",
      "| Support Vector Machine    | 95.28%   | 43.22%   | 96.10%  | 59.63% |\n",
      "| Gradient Boosting         | 99.68%   | 92.13%   | 99.65%  | 95.74% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions = run_all_motors('data_motor_2_label',drop_list1_label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions, best_params2 = run_all_motors_validation(2, drop_list1_label2)\n",
    "#model_predictions, best_params2 = run_all_motors_validation(2, drop_list2_label2)\n",
    "\n",
    "#y_pred2_Gradient_Boosting = model_predictions['y_pred_Gradient_Boosting'] # a minimum of 2 classes are required.\n",
    "y_pred2_Logistic_Regression = model_predictions['y_pred_Logistic_Regression'] # The number of classes has to be greater than one; got 1 class\n",
    "#y_pred2_Decision_Tree = model_predictions['y_pred_Decision_Tree']\n",
    "#y_pred2_Random_Forest= model_predictions['y_pred_Random_Forest']\n",
    "y_pred2_SVC= model_predictions['y_pred_Support_Vector_Machine'] # The number of classes has to be greater than one; got 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'model__max_depth': 20},\n",
       " 'Random Forest': {'model__min_samples_split': 4, 'model__n_estimators': 100},\n",
       " 'Gradient Boosting': {'model__learning_rate': 0.1,\n",
       "  'model__n_estimators': 300}}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1_label3 = ['data_motor_1_voltage','data_motor_2_voltage', 'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage']\n",
    "drop_list2_label3 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                    | Accuracy | Precision | Recall | F1    |\n",
      "|--------------------------|----------|-----------|--------|-------|\n",
      "| Logistic Regression       | 85.34%   | 19.50%   | 97.16%  | 32.48% |\n",
      "| Decision Tree             | 99.46%   | 87.74%   | 98.94%  | 93.00% |\n",
      "| Random Forest             | 99.88%   | 97.56%   | 99.29%  | 98.42% |\n",
      "| Support Vector Machine    | 95.46%   | 44.21%   | 96.10%  | 60.56% |\n",
      "| Gradient Boosting         | 99.83%   | 96.22%   | 99.29%  | 97.73% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions = run_all_motors('data_motor_3_label',drop_list1_label3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions, best_params3 = run_all_motors_validation(3, drop_list1_label3)\n",
    "#model_predictions, best_params3 = run_all_motors_validation(3, drop_list2_label3)\n",
    "\n",
    "#y_pred3_Gradient_Boosting = model_predictions['y_pred_Gradient_Boosting']\n",
    "y_pred3_Logistic_Regression = model_predictions['y_pred_Logistic_Regression']\n",
    "#y_pred3_Decision_Tree = model_predictions['y_pred_Decision_Tree']\n",
    "#y_pred3_Random_Forest= model_predictions['y_pred_Random_Forest']\n",
    "y_pred3_SVC= model_predictions['y_pred_Support_Vector_Machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'model__max_depth': 20},\n",
       " 'Random Forest': {'model__min_samples_split': 2, 'model__n_estimators': 100},\n",
       " 'Gradient Boosting': {'model__learning_rate': 0.5,\n",
       "  'model__n_estimators': 300}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1_label4= ['data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage', 'data_motor_5_temperature']\n",
    "drop_list2_label4 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                    | Accuracy | Precision | Recall | F1    |\n",
      "|--------------------------|----------|-----------|--------|-------|\n",
      "| Logistic Regression       | 85.56%   | 19.57%   | 95.74%  | 32.49% |\n",
      "| Decision Tree             | 99.21%   | 82.79%   | 98.94%  | 90.15% |\n",
      "| Random Forest             | 99.90%   | 97.90%   | 99.29%  | 98.59% |\n",
      "| Support Vector Machine    | 95.64%   | 45.21%   | 95.39%  | 61.35% |\n",
      "| Gradient Boosting         | 99.88%   | 97.56%   | 99.29%  | 98.42% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions = run_all_motors('data_motor_4_label',drop_list1_label4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions,best_params4 = run_all_motors_validation(4, drop_list1_label4)\n",
    "#model_predictions,best_params4 = run_all_motors_validation(4, drop_list2_label4)\n",
    "\n",
    "#y_pred4_Gradient_Boosting = model_predictions['y_pred_Gradient_Boosting']\n",
    "y_pred4_Logistic_Regression = model_predictions['y_pred_Logistic_Regression']\n",
    "#y_pred4_Decision_Tree = model_predictions['y_pred_Decision_Tree']\n",
    "#y_pred4_Random_Forest= model_predictions['y_pred_Random_Forest']\n",
    "y_pred4_SVC= model_predictions['y_pred_Support_Vector_Machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'model__max_depth': 30},\n",
       " 'Random Forest': {'model__n_estimators': 150}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1_label5 = ['data_motor_1_voltage','data_motor_2_voltage', 'data_motor_3_voltage', 'data_motor_4_voltage', 'data_motor_6_voltage']\n",
    "drop_list2_label5 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                    | Accuracy | Precision | Recall | F1    |\n",
      "|--------------------------|----------|-----------|--------|-------|\n",
      "| Logistic Regression       | 89.52%   | 25.46%   | 97.87%  | 40.41% |\n",
      "| Decision Tree             | 99.11%   | 81.05%   | 98.58%  | 88.96% |\n",
      "| Random Forest             | 99.83%   | 96.22%   | 99.29%  | 97.73% |\n",
      "| Support Vector Machine    | 95.17%   | 42.70%   | 96.45%  | 59.19% |\n",
      "| Gradient Boosting         | 99.34%   | 84.89%   | 99.65%  | 91.68% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions = run_all_motors('data_motor_5_label',drop_list1_label5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions, best_params5 = run_all_motors_validation(5, drop_list1_label5)\n",
    "#model_predictions, best_params5 = run_all_motors_validation(5, drop_list2_label5)\n",
    "\n",
    "#y_pred5_Gradient_Boosting = model_predictions['y_pred_Gradient_Boosting']\n",
    "y_pred5_Logistic_Regression = model_predictions['y_pred_Logistic_Regression']\n",
    "#y_pred5_Decision_Tree = model_predictions['y_pred_Decision_Tree']\n",
    "#y_pred5_Random_Forest= model_predictions['y_pred_Random_Forest']\n",
    "y_pred5_SVC= model_predictions['y_pred_Support_Vector_Machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'model__max_depth': 20},\n",
       " 'Random Forest': {'model__n_estimators': 150}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1_label6 = ['data_motor_1_voltage','data_motor_2_voltage', 'data_motor_3_voltage', 'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_position']\n",
    "drop_list2_label6 = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                    | Accuracy | Precision | Recall | F1    |\n",
      "|--------------------------|----------|-----------|--------|-------|\n",
      "| Logistic Regression       | 83.50%   | 17.66%   | 96.81%  | 29.87% |\n",
      "| Decision Tree             | 99.42%   | 86.69%   | 99.29%  | 92.56% |\n",
      "| Random Forest             | 99.86%   | 97.21%   | 98.94%  | 98.07% |\n",
      "| Support Vector Machine    | 95.83%   | 46.40%   | 96.10%  | 62.59% |\n",
      "| Gradient Boosting         | 99.87%   | 96.90%   | 99.65%  | 98.25% |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions = run_all_motors('data_motor_6_label',drop_list1_label6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions, best_params6 = run_all_motors_validation(6, drop_list1_label6)\n",
    "#model_predictions, best_params6 = run_all_motors_validation(6, drop_list2_label6)\n",
    "\n",
    "#y_pred6_Gradient_Boosting = model_predictions['y_pred_Gradient_Boosting']\n",
    "y_pred6_Logistic_Regression = model_predictions['y_pred_Logistic_Regression']\n",
    "#y_pred6_Decision_Tree = model_predictions['y_pred_Decision_Tree']\n",
    "#y_pred6_Random_Forest= model_predictions['y_pred_Random_Forest']\n",
    "y_pred6_SVC= model_predictions['y_pred_Support_Vector_Machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'model__max_depth': 30},\n",
       " 'Random Forest': {'model__n_estimators': 150}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create csv file for submit Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic_Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Logistic_Regression = {\n",
    "    'idx': range(len(y_pred1_Logistic_Regression)),\n",
    "    'data_motor_1_label': y_pred1_Logistic_Regression,\n",
    "    'data_motor_2_label': y_pred2_Logistic_Regression,\n",
    "    'data_motor_3_label': y_pred3_Logistic_Regression,\n",
    "    'data_motor_4_label': y_pred4_Logistic_Regression,\n",
    "    'data_motor_5_label': y_pred5_Logistic_Regression,\n",
    "    'data_motor_6_label': y_pred6_Logistic_Regression\n",
    "}\n",
    "\n",
    "df_Logistic_Regression = pd.DataFrame(data_Logistic_Regression)\n",
    "df_Logistic_Regression.to_csv('motor_predictions_Logistic_Regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SVC = {\n",
    "    'idx': range(len(y_pred1_SVC)),\n",
    "    'data_motor_1_label': y_pred1_SVC,\n",
    "    'data_motor_2_label': y_pred2_SVC,\n",
    "    'data_motor_3_label': y_pred3_SVC,\n",
    "    'data_motor_4_label': y_pred4_SVC,\n",
    "    'data_motor_5_label': y_pred5_SVC,\n",
    "    'data_motor_6_label': y_pred6_SVC\n",
    "}\n",
    "\n",
    "df_SVC = pd.DataFrame(data_SVC)\n",
    "\n",
    "df_SVC.to_csv('motor_predictions_SVC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient_Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Gradient_Boosting = {\n",
    "    'idx': range(len(y_pred1_Gradient_Boosting)),\n",
    "    'data_motor_1_label': y_pred1_Gradient_Boosting,\n",
    "    'data_motor_2_label': y_pred2_Gradient_Boosting,\n",
    "    'data_motor_3_label': y_pred3_Gradient_Boosting,\n",
    "    'data_motor_4_label': y_pred4_Gradient_Boosting,\n",
    "    'data_motor_5_label': y_pred5_Gradient_Boosting,\n",
    "    'data_motor_6_label': y_pred6_Gradient_Boosting\n",
    "}\n",
    "\n",
    "df_Gradient_Boosting = pd.DataFrame(data_Gradient_Boosting)\n",
    "\n",
    "df_Gradient_Boosting.to_csv('motor_predictions_Gradient_Boosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random_Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Random_Forest = {\n",
    "    'idx': range(len(y_pred1_Random_Forest)),\n",
    "    'data_motor_1_label': y_pred1_Random_Forest,\n",
    "    'data_motor_2_label': y_pred2_Random_Forest,\n",
    "    'data_motor_3_label': y_pred2_Random_Forest,\n",
    "    'data_motor_4_label': y_pred4_Random_Forest,\n",
    "    'data_motor_5_label': y_pred5_Random_Forest,\n",
    "    'data_motor_6_label': y_pred6_Random_Forest\n",
    "}\n",
    "\n",
    "df_Random_Forest = pd.DataFrame(data_Random_Forest)\n",
    "\n",
    "df_Random_Forest.to_csv('motor_predictions_Random_Forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision_Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Decision_Tree = {\n",
    "    'idx': range(len(y_pred1_Decision_Tree)),\n",
    "    'data_motor_1_label': y_pred1_Decision_Tree,\n",
    "    'data_motor_2_label': y_pred2_Decision_Tree,\n",
    "    'data_motor_3_label': y_pred3_Decision_Tree,\n",
    "    'data_motor_4_label': y_pred4_Decision_Tree,\n",
    "    'data_motor_5_label': y_pred5_Decision_Tree,\n",
    "    'data_motor_6_label': y_pred6_Decision_Tree\n",
    "}\n",
    "\n",
    "df_Decision_Tree = pd.DataFrame(data_Decision_Tree)\n",
    "\n",
    "df_Decision_Tree.to_csv('motor_predictions_Decision_Tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the best results\n",
    "\n",
    "| Model   | Drop_list | window_size | sample_step | F1   |\n",
    "|---------|----------|-------------|-------------|------|\n",
    "| Logistic Regression | 2 | 70 | 30 | 0.37|\n",
    "| SVC | 2 | 70 | 30 | 0.45|\n",
    "| Random Forest | 2 | 70 | 30 | 0.13 | \n",
    "| Decision Tree  |  2 | 70 | 30 |  0.19 | \n",
    "| Gradient Boosting  |  2 | 70 | 30 | 0.12 | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
